{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a7aeb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tune-sklearn in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (0.4.1)\n",
      "Requirement already satisfied: ray[tune] in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (1.8.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from tune-sklearn) (1.0.1)\n",
      "Requirement already satisfied: scipy in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from tune-sklearn) (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.16 in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from tune-sklearn) (1.21.4)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from ray[tune]) (1.0.3)\n",
      "Requirement already satisfied: grpcio>=1.28.1 in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from ray[tune]) (1.42.0)\n",
      "Requirement already satisfied: pyyaml in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from ray[tune]) (6.0)\n",
      "Requirement already satisfied: jsonschema in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from ray[tune]) (4.2.1)\n",
      "Requirement already satisfied: protobuf>=3.15.3 in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from ray[tune]) (3.19.1)\n",
      "Requirement already satisfied: redis>=3.5.0 in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from ray[tune]) (4.0.2)\n",
      "Requirement already satisfied: click>=7.0 in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from ray[tune]) (8.0.3)\n",
      "Requirement already satisfied: filelock in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from ray[tune]) (3.4.0)\n",
      "Requirement already satisfied: attrs in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from ray[tune]) (21.2.0)\n",
      "Requirement already satisfied: tabulate in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from ray[tune]) (0.8.9)\n",
      "Requirement already satisfied: requests in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from ray[tune]) (2.26.0)\n",
      "Requirement already satisfied: pandas in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from ray[tune]) (1.3.4)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from ray[tune]) (2.4.1)\n",
      "Requirement already satisfied: six>=1.5.2 in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from grpcio>=1.28.1->ray[tune]) (1.16.0)\n",
      "Requirement already satisfied: deprecated in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from redis>=3.5.0->ray[tune]) (1.2.13)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from deprecated->redis>=3.5.0->ray[tune]) (1.13.3)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from jsonschema->ray[tune]) (0.18.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from pandas->ray[tune]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from pandas->ray[tune]) (2021.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from requests->ray[tune]) (2.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from requests->ray[tune]) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from requests->ray[tune]) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from requests->ray[tune]) (2021.10.8)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from scikit-learn->tune-sklearn) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from scikit-learn->tune-sklearn) (1.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: cloudpickle in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (2.0.0)\n",
      "Requirement already satisfied: imbalanced-learn in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (0.8.1)\n",
      "Requirement already satisfied: scikit-optimize in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (0.9.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from imbalanced-learn) (1.7.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from imbalanced-learn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from imbalanced-learn) (1.21.4)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from imbalanced-learn) (1.0.1)\n",
      "Requirement already satisfied: pyaml>=16.9 in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from scikit-optimize) (21.10.1)\n",
      "Requirement already satisfied: PyYAML in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/lib/python3.9/site-packages (from scikit-learn>=0.24->imbalanced-learn) (3.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 21.3.1 is available.\r\n",
      "You should consider upgrading via the '/Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/venvs/sustainbench/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tune-sklearn \"ray[tune]\"\n",
    "!pip3 install cloudpickle imbalanced-learn scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "388d8b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "sys.path.append('/Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction')\n",
    "\n",
    "from utils.get_data_loader import SustainBenchTextDataset\n",
    "from sklearn.linear_model import Ridge, LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import time # Just to compare fit times\n",
    "from sklearn.metrics import r2_score, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6c737aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_cutoff_dict = {'asset_index': 0, 'sanitation_index': 3, 'water_index': 3, 'women_edu': 5}\n",
    "TARGETS = ['asset_index', 'sanitation_index', 'water_index', 'women_edu']\n",
    "FEATURE_TYPES = ['target_sentence', 'document', 'target_sentence_document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea8928d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def evaluate_hyperparameter_optimization_regression(X_train, y_train, X_test, y_test):\n",
    "    clf = Ridge()\n",
    "    \n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print(f'baseline fit time: {end - start}, r^2: {round(r2_score(y_test, y_pred), 5)}')\n",
    "\n",
    "    \n",
    "    parameters = {\n",
    "       'alpha': np.logspace(-2,2,50)\n",
    "    }\n",
    "    # n_jobs=-1 enables use of all cores like Tune does\n",
    "    sklearn_search = GridSearchCV(\n",
    "       Ridge(),\n",
    "       parameters,\n",
    "       n_jobs=-1\n",
    "    )\n",
    "\n",
    "    start = time.time()\n",
    "    sklearn_search.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    y_pred = sklearn_search.predict(X_test)\n",
    "    \n",
    "    print(f'sklearn GridSearchCV fit time: {end - start}, r^2: {round(r2_score(y_test, y_pred), 5)}')\n",
    "    print(sklearn_search.best_estimator_)\n",
    "    print()\n",
    "\n",
    "    \n",
    "def evaluate_hyperparameter_optimization_classification(X_train, y_train, X_test, y_test, use_smote=True):\n",
    "    if use_smote:\n",
    "        oversample = SMOTE()\n",
    "        X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "    for model in ['svm', 'lr', 'rf']:\n",
    "        print(model)\n",
    "        if model == 'svm':\n",
    "            base_estimator = Pipeline(steps=[(\"scaler\", MaxAbsScaler()), (\"svm\", SVC(gamma='scale'))])\n",
    "            param_grid = {'svm__kernel': ('linear', 'rbf'),'svm__C': np.logspace(-1,2,20)}\n",
    "            sklearn_search = HalvingGridSearchCV(\n",
    "                base_estimator, \n",
    "                param_grid, \n",
    "                cv=3,\n",
    "                factor=2,\n",
    "                max_resources=100,\n",
    "                scoring='accuracy',\n",
    "                error_score=0\n",
    "            )\n",
    "        elif model == 'lr':\n",
    "            base_estimator = Pipeline(steps=[(\"scaler\", MaxAbsScaler()), (\"lr\", LogisticRegression(max_iter=500))])\n",
    "            param_grid = {'lr__C': np.logspace(-1,2,20)}\n",
    "            sklearn_search = HalvingGridSearchCV(\n",
    "                base_estimator, \n",
    "                param_grid, \n",
    "                cv=3,\n",
    "                factor=2,\n",
    "                max_resources=100,\n",
    "                scoring='accuracy',\n",
    "                error_score=0\n",
    "            )\n",
    "        else:\n",
    "            base_estimator = RandomForestClassifier(random_state=0)\n",
    "            param_grid = {'max_depth': [3, 5, 10], 'min_samples_split': [2, 5, 10]}\n",
    "            sklearn_search = HalvingGridSearchCV(\n",
    "                base_estimator, \n",
    "                param_grid, \n",
    "                cv=3,\n",
    "                factor=2,\n",
    "                resource='n_estimators',\n",
    "                max_resources=100,\n",
    "                scoring='accuracy',\n",
    "                error_score=0\n",
    "            )\n",
    "\n",
    "        start = time.time()\n",
    "        sklearn_search.fit(X_train, y_train)\n",
    "        end = time.time()\n",
    "        y_pred = sklearn_search.predict(X_test)\n",
    "\n",
    "        print(f'sklearn HalvingGridSearchCV fit time: {end - start}, roc auc: {round(roc_auc_score(y_test, y_pred), 5)}')\n",
    "        print(sklearn_search.best_estimator_)\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f9f0e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asset_index target_sentence\n",
      "(2017, 384) (401, 384)\n",
      "svm\n",
      "sklearn HalvingGridSearchCV fit time: 0.8768939971923828, roc auc: 0.73741\n",
      "Pipeline(steps=[('scaler', MaxAbsScaler()), ('svm', SVC(C=1.8329807108324356))])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.70      0.75       237\n",
      "           1       0.64      0.77      0.70       164\n",
      "\n",
      "    accuracy                           0.73       401\n",
      "   macro avg       0.73      0.74      0.73       401\n",
      "weighted avg       0.75      0.73      0.73       401\n",
      "\n",
      "\n",
      "lr\n",
      "sklearn HalvingGridSearchCV fit time: 0.8643078804016113, roc auc: 0.6603\n",
      "Pipeline(steps=[('scaler', MaxAbsScaler()),\n",
      "                ('lr', LogisticRegression(C=33.59818286283781, max_iter=500))])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.49      0.61       237\n",
      "           1       0.53      0.84      0.65       164\n",
      "\n",
      "    accuracy                           0.63       401\n",
      "   macro avg       0.67      0.66      0.63       401\n",
      "weighted avg       0.69      0.63      0.62       401\n",
      "\n",
      "\n",
      "rf\n",
      "sklearn HalvingGridSearchCV fit time: 25.690373182296753, roc auc: 0.7217\n",
      "RandomForestClassifier(max_depth=10, n_estimators=96, random_state=0)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.68      0.74       237\n",
      "           1       0.62      0.77      0.69       164\n",
      "\n",
      "    accuracy                           0.71       401\n",
      "   macro avg       0.71      0.72      0.71       401\n",
      "weighted avg       0.73      0.71      0.72       401\n",
      "\n",
      "\n",
      "asset_index target_sentence_document\n",
      "(2017, 684) (401, 684)\n",
      "svm\n",
      "sklearn HalvingGridSearchCV fit time: 1.3144168853759766, roc auc: 0.7306\n",
      "Pipeline(steps=[('scaler', MaxAbsScaler()), ('svm', SVC(C=5.455594781168517))])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76       237\n",
      "           1       0.65      0.74      0.69       164\n",
      "\n",
      "    accuracy                           0.73       401\n",
      "   macro avg       0.72      0.73      0.72       401\n",
      "weighted avg       0.74      0.73      0.73       401\n",
      "\n",
      "\n",
      "lr\n",
      "sklearn HalvingGridSearchCV fit time: 0.8061809539794922, roc auc: 0.68444\n",
      "Pipeline(steps=[('scaler', MaxAbsScaler()),\n",
      "                ('lr', LogisticRegression(C=0.6158482110660264, max_iter=500))])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.53      0.64       237\n",
      "           1       0.55      0.84      0.67       164\n",
      "\n",
      "    accuracy                           0.66       401\n",
      "   macro avg       0.69      0.68      0.66       401\n",
      "weighted avg       0.72      0.66      0.65       401\n",
      "\n",
      "\n",
      "rf\n",
      "sklearn HalvingGridSearchCV fit time: 34.58208084106445, roc auc: 0.7304\n",
      "RandomForestClassifier(max_depth=10, min_samples_split=5, n_estimators=96,\n",
      "                       random_state=0)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.59      0.71       237\n",
      "           1       0.60      0.87      0.71       164\n",
      "\n",
      "    accuracy                           0.71       401\n",
      "   macro avg       0.73      0.73      0.71       401\n",
      "weighted avg       0.76      0.71      0.71       401\n",
      "\n",
      "\n",
      "sanitation_index target_sentence\n",
      "(2619, 384) (620, 384)\n",
      "svm\n",
      "sklearn HalvingGridSearchCV fit time: 1.3211400508880615, roc auc: 0.64786\n",
      "Pipeline(steps=[('scaler', MaxAbsScaler()), ('svm', SVC(C=7.847599703514611))])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.74      0.67       296\n",
      "           1       0.70      0.55      0.62       324\n",
      "\n",
      "    accuracy                           0.64       620\n",
      "   macro avg       0.65      0.65      0.64       620\n",
      "weighted avg       0.65      0.64      0.64       620\n",
      "\n",
      "\n",
      "lr\n",
      "sklearn HalvingGridSearchCV fit time: 0.5613300800323486, roc auc: 0.68106\n",
      "Pipeline(steps=[('scaler', MaxAbsScaler()),\n",
      "                ('lr',\n",
      "                 LogisticRegression(C=0.20691380811147897, max_iter=500))])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.55      0.63       296\n",
      "           1       0.66      0.81      0.73       324\n",
      "\n",
      "    accuracy                           0.69       620\n",
      "   macro avg       0.70      0.68      0.68       620\n",
      "weighted avg       0.70      0.69      0.68       620\n",
      "\n",
      "\n",
      "rf\n",
      "sklearn HalvingGridSearchCV fit time: 31.063239097595215, roc auc: 0.67964\n",
      "RandomForestClassifier(max_depth=10, min_samples_split=5, n_estimators=96,\n",
      "                       random_state=0)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65       296\n",
      "           1       0.68      0.74      0.71       324\n",
      "\n",
      "    accuracy                           0.68       620\n",
      "   macro avg       0.68      0.68      0.68       620\n",
      "weighted avg       0.68      0.68      0.68       620\n",
      "\n",
      "\n",
      "sanitation_index target_sentence_document\n",
      "(2619, 684) (620, 684)\n",
      "svm\n",
      "sklearn HalvingGridSearchCV fit time: 2.092827796936035, roc auc: 0.70506\n",
      "Pipeline(steps=[('scaler', MaxAbsScaler()), ('svm', SVC(C=0.8858667904100825))])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.64      0.68       296\n",
      "           1       0.70      0.77      0.73       324\n",
      "\n",
      "    accuracy                           0.71       620\n",
      "   macro avg       0.71      0.71      0.71       620\n",
      "weighted avg       0.71      0.71      0.71       620\n",
      "\n",
      "\n",
      "lr\n",
      "sklearn HalvingGridSearchCV fit time: 0.7766647338867188, roc auc: 0.65336\n",
      "Pipeline(steps=[('scaler', MaxAbsScaler()),\n",
      "                ('lr',\n",
      "                 LogisticRegression(C=0.20691380811147897, max_iter=500))])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.51      0.59       296\n",
      "           1       0.64      0.79      0.71       324\n",
      "\n",
      "    accuracy                           0.66       620\n",
      "   macro avg       0.67      0.65      0.65       620\n",
      "weighted avg       0.67      0.66      0.65       620\n",
      "\n",
      "\n",
      "rf\n",
      "sklearn HalvingGridSearchCV fit time: 41.95771598815918, roc auc: 0.62116\n",
      "RandomForestClassifier(max_depth=10, n_estimators=96, random_state=0)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.55      0.58       296\n",
      "           1       0.63      0.69      0.66       324\n",
      "\n",
      "    accuracy                           0.62       620\n",
      "   macro avg       0.62      0.62      0.62       620\n",
      "weighted avg       0.62      0.62      0.62       620\n",
      "\n",
      "\n",
      "water_index target_sentence\n",
      "(3214, 384) (632, 384)\n",
      "svm\n",
      "sklearn HalvingGridSearchCV fit time: 1.4193341732025146, roc auc: 0.51439\n",
      "Pipeline(steps=[('scaler', MaxAbsScaler()), ('svm', SVC(C=48.32930238571752))])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.90      0.82       467\n",
      "           1       0.31      0.13      0.18       165\n",
      "\n",
      "    accuracy                           0.70       632\n",
      "   macro avg       0.53      0.51      0.50       632\n",
      "weighted avg       0.63      0.70      0.65       632\n",
      "\n",
      "\n",
      "lr\n",
      "sklearn HalvingGridSearchCV fit time: 0.7292168140411377, roc auc: 0.62971\n",
      "Pipeline(steps=[('scaler', MaxAbsScaler()),\n",
      "                ('lr',\n",
      "                 LogisticRegression(C=0.42813323987193935, max_iter=500))])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.55      0.67       467\n",
      "           1       0.36      0.71      0.48       165\n",
      "\n",
      "    accuracy                           0.59       632\n",
      "   macro avg       0.60      0.63      0.57       632\n",
      "weighted avg       0.72      0.59      0.62       632\n",
      "\n",
      "\n",
      "rf\n",
      "sklearn HalvingGridSearchCV fit time: 50.04847812652588, roc auc: 0.58437\n",
      "RandomForestClassifier(max_depth=10, min_samples_split=5, n_estimators=96,\n",
      "                       random_state=0)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.78       467\n",
      "           1       0.38      0.40      0.39       165\n",
      "\n",
      "    accuracy                           0.67       632\n",
      "   macro avg       0.58      0.58      0.58       632\n",
      "weighted avg       0.68      0.67      0.68       632\n",
      "\n",
      "\n",
      "water_index target_sentence_document\n",
      "(3214, 684) (632, 684)\n",
      "svm\n",
      "sklearn HalvingGridSearchCV fit time: 218.78206491470337, roc auc: 0.5654\n",
      "Pipeline(steps=[('scaler', MaxAbsScaler()),\n",
      "                ('svm', SVC(C=69.51927961775606, kernel='linear'))])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.63      0.70       467\n",
      "           1       0.32      0.50      0.39       165\n",
      "\n",
      "    accuracy                           0.60       632\n",
      "   macro avg       0.55      0.57      0.55       632\n",
      "weighted avg       0.66      0.60      0.62       632\n",
      "\n",
      "\n",
      "lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn HalvingGridSearchCV fit time: 0.9061110019683838, roc auc: 0.62241\n",
      "Pipeline(steps=[('scaler', MaxAbsScaler()),\n",
      "                ('lr',\n",
      "                 LogisticRegression(C=0.14384498882876628, max_iter=500))])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.58      0.68       467\n",
      "           1       0.36      0.67      0.47       165\n",
      "\n",
      "    accuracy                           0.60       632\n",
      "   macro avg       0.59      0.62      0.57       632\n",
      "weighted avg       0.71      0.60      0.63       632\n",
      "\n",
      "\n",
      "rf\n",
      "sklearn HalvingGridSearchCV fit time: 68.34827589988708, roc auc: 0.54021\n",
      "RandomForestClassifier(max_depth=10, min_samples_split=5, n_estimators=96,\n",
      "                       random_state=0)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80       467\n",
      "           1       0.35      0.23      0.28       165\n",
      "\n",
      "    accuracy                           0.69       632\n",
      "   macro avg       0.55      0.54      0.54       632\n",
      "weighted avg       0.65      0.69      0.66       632\n",
      "\n",
      "\n",
      "women_edu target_sentence\n",
      "(4338, 384) (1395, 384)\n",
      "svm\n",
      "sklearn HalvingGridSearchCV fit time: 3.114022731781006, roc auc: 0.61924\n",
      "Pipeline(steps=[('scaler', MaxAbsScaler()), ('svm', SVC(C=23.357214690901213))])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.87      0.61       545\n",
      "           1       0.81      0.37      0.51       850\n",
      "\n",
      "    accuracy                           0.56      1395\n",
      "   macro avg       0.64      0.62      0.56      1395\n",
      "weighted avg       0.68      0.56      0.55      1395\n",
      "\n",
      "\n",
      "lr\n",
      "sklearn HalvingGridSearchCV fit time: 0.956732988357544, roc auc: 0.65368\n",
      "Pipeline(steps=[('scaler', MaxAbsScaler()),\n",
      "                ('lr', LogisticRegression(C=0.6158482110660264, max_iter=500))])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.52      0.56       545\n",
      "           1       0.72      0.79      0.75       850\n",
      "\n",
      "    accuracy                           0.68      1395\n",
      "   macro avg       0.67      0.65      0.66      1395\n",
      "weighted avg       0.68      0.68      0.68      1395\n",
      "\n",
      "\n",
      "rf\n",
      "sklearn HalvingGridSearchCV fit time: 67.89008593559265, roc auc: 0.7003\n",
      "RandomForestClassifier(max_depth=10, n_estimators=96, random_state=0)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.68      0.64       545\n",
      "           1       0.78      0.72      0.75       850\n",
      "\n",
      "    accuracy                           0.71      1395\n",
      "   macro avg       0.69      0.70      0.70      1395\n",
      "weighted avg       0.71      0.71      0.71      1395\n",
      "\n",
      "\n",
      "women_edu target_sentence_document\n",
      "(4338, 684) (1395, 684)\n",
      "svm\n",
      "sklearn HalvingGridSearchCV fit time: 4.771787881851196, roc auc: 0.66806\n",
      "Pipeline(steps=[('scaler', MaxAbsScaler()), ('svm', SVC(C=16.23776739188721))])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.87      0.64       545\n",
      "           1       0.85      0.47      0.60       850\n",
      "\n",
      "    accuracy                           0.62      1395\n",
      "   macro avg       0.68      0.67      0.62      1395\n",
      "weighted avg       0.72      0.62      0.62      1395\n",
      "\n",
      "\n",
      "lr\n",
      "sklearn HalvingGridSearchCV fit time: 1.0526301860809326, roc auc: 0.62678\n",
      "Pipeline(steps=[('scaler', MaxAbsScaler()),\n",
      "                ('lr',\n",
      "                 LogisticRegression(C=0.29763514416313175, max_iter=500))])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.54      0.54       545\n",
      "           1       0.71      0.71      0.71       850\n",
      "\n",
      "    accuracy                           0.65      1395\n",
      "   macro avg       0.63      0.63      0.63      1395\n",
      "weighted avg       0.64      0.65      0.65      1395\n",
      "\n",
      "\n",
      "rf\n",
      "sklearn HalvingGridSearchCV fit time: 92.60996699333191, roc auc: 0.67098\n",
      "RandomForestClassifier(max_depth=10, min_samples_split=5, n_estimators=96,\n",
      "                       random_state=0)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.65      0.61       545\n",
      "           1       0.76      0.69      0.72       850\n",
      "\n",
      "    accuracy                           0.68      1395\n",
      "   macro avg       0.66      0.67      0.67      1395\n",
      "weighted avg       0.68      0.68      0.68      1395\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for target in TARGETS:\n",
    "    for feature_type in [\n",
    "        'target_sentence', \n",
    "#         'document', \n",
    "        'target_sentence_document'\n",
    "    ]:\n",
    "        ds = SustainBenchTextDataset(\n",
    "            data_dir=f'/Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/data/', \n",
    "            feature_type=feature_type, \n",
    "            target=target,\n",
    "            model_type='classification',\n",
    "            classification_cutoff=classification_cutoff_dict[target]\n",
    "        )\n",
    "\n",
    "        print(target, feature_type)\n",
    "        X_train, y_train = ds.get_data('train')\n",
    "        X_test, y_test = ds.get_data('test')\n",
    "        print(X_train.shape, X_test.shape)\n",
    "\n",
    "        evaluate_hyperparameter_optimization_classification(X_train, y_train, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de797d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asset_index target_sentence\n",
      "(2017, 384) (401, 384)\n",
      "baseline fit time: 0.025072097778320312, r^2: 0.39316\n",
      "sklearn GridSearchCV fit time: 1.3284289836883545, r^2: 0.3891\n",
      "Ridge(alpha=1.0985411419875584)\n",
      "\n",
      "asset_index target_sentence_document\n",
      "(2017, 684) (401, 684)\n",
      "baseline fit time: 0.036002159118652344, r^2: 0.33216\n",
      "sklearn GridSearchCV fit time: 3.220874071121216, r^2: 0.13692\n",
      "Ridge(alpha=100.0)\n",
      "\n",
      "sanitation_index target_sentence\n",
      "(2619, 384) (620, 384)\n",
      "baseline fit time: 0.01630687713623047, r^2: 0.21119\n",
      "sklearn GridSearchCV fit time: 1.4730379581451416, r^2: 0.20939\n",
      "Ridge(alpha=1.0985411419875584)\n",
      "\n",
      "sanitation_index target_sentence_document\n",
      "(2619, 684) (620, 684)\n",
      "baseline fit time: 0.04382205009460449, r^2: 0.17058\n",
      "sklearn GridSearchCV fit time: 4.094425916671753, r^2: 0.15565\n",
      "Ridge(alpha=1.5998587196060574)\n",
      "\n",
      "water_index target_sentence\n",
      "(3214, 384) (632, 384)\n",
      "baseline fit time: 0.020295143127441406, r^2: 0.09664\n",
      "sklearn GridSearchCV fit time: 1.7417972087860107, r^2: 0.10047\n",
      "Ridge(alpha=1.9306977288832496)\n",
      "\n",
      "water_index target_sentence_document\n",
      "(3214, 684) (632, 684)\n",
      "baseline fit time: 0.04576396942138672, r^2: 0.00163\n",
      "sklearn GridSearchCV fit time: 4.9536120891571045, r^2: -0.00224\n",
      "Ridge(alpha=1.9306977288832496)\n",
      "\n",
      "women_edu target_sentence\n",
      "(4338, 384) (1395, 384)\n",
      "baseline fit time: 0.02372288703918457, r^2: -0.11601\n",
      "sklearn GridSearchCV fit time: 2.3220510482788086, r^2: -0.27519\n",
      "Ridge(alpha=7.196856730011514)\n",
      "\n",
      "women_edu target_sentence_document\n",
      "(4338, 684) (1395, 684)\n",
      "baseline fit time: 0.060559749603271484, r^2: -0.13022\n",
      "sklearn GridSearchCV fit time: 6.734483242034912, r^2: -0.18334\n",
      "Ridge(alpha=3.3932217718953264)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for target in TARGETS:\n",
    "    for feature_type in [\n",
    "        'target_sentence', \n",
    "#         'document', \n",
    "        'target_sentence_document'\n",
    "    ]:\n",
    "        ds = SustainBenchTextDataset(\n",
    "            data_dir=f'/Users/caravanuden/git-repos/Multimodal-deep-learning-for-poverty-prediction/data/', \n",
    "            feature_type=feature_type, \n",
    "            target=target,\n",
    "            model_type='regression',\n",
    "            classification_cutoff=classification_cutoff_dict[target]\n",
    "        )\n",
    "\n",
    "        print(target, feature_type)\n",
    "        X_train, y_train = ds.get_data('train')\n",
    "        X_test, y_test = ds.get_data('test')\n",
    "        print(X_train.shape, X_test.shape)\n",
    "        \n",
    "        evaluate_hyperparameter_optimization_regression(X_train, y_train, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aa7757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
